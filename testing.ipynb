{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = joblib.load('xgboost.pkl')\n",
    "\n",
    "test_accuracy_data = pd.read_csv('test_target.csv')\n",
    "test_data = pd.read_csv('test_data_undersampled.csv').drop(columns=['Unnamed: 0'])\n",
    "\n",
    "test_data['Service Type'] = test_data['Service Type'].map({'Van' : 1, 'Motorcycle' : 0})\n",
    "test_data['Response Distance'] = test_data['Response Distance'].round().fillna(0.0).astype(int)\n",
    "test_data['Response Distance'] = test_data['Response Distance'] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model.predict([-0.90986512, -0.75978697,  0.29754476,  1.71774662,  1.00731086,\n",
    "       -0.35633625, -0.05579893])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_xgboost(df):\n",
    "    \n",
    "    sc = StandardScaler().fit_transform(df)\n",
    "    \n",
    "    xgboost_model = joblib.load('xgboost.pkl')\n",
    "    \n",
    "    xgboost_pred = xgboost_model.predict(sc)\n",
    "    \n",
    "    predictions = pd.DataFrame(data=xgboost_pred, columns=['Outcome'])\n",
    "    \n",
    "    accuracy = accuracy_score(test_accuracy_data.values, predictions)\n",
    "    \n",
    "    report = classification_report(test_accuracy_data.values, predictions)\n",
    "    \n",
    "    probability = xgboost_model.predict_proba(sc)\n",
    "    \n",
    "    #predictions['Outcome'] = predictions['Outcome'].map({'0' : 'Fulfilled', '1' : 'Cancelled'})\n",
    "    \n",
    "    return round(accuracy *100, 2) , report, probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Available Drivers  Response Distance  Service Type  day  tempC  \\\n",
      "0                 13              45.30             1    2     31   \n",
      "1                210              29.08             1    2     31   \n",
      "2                 50              23.59             0    5     32   \n",
      "3                143              35.02             1    1     31   \n",
      "4                312              17.68             1    2     31   \n",
      "\n",
      "   windspeedKmph  cloudcover  \n",
      "0              5          13  \n",
      "1              5          13  \n",
      "2             13          17  \n",
      "3             11          24  \n",
      "4              5          13  \n"
     ]
    }
   ],
   "source": [
    "# LETS TEST THE MODEL WITH TEST DATA\n",
    "\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score  67.68\n",
      "\n",
      "\n",
      "Classification report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.92      0.74       783\n",
      "           1       0.83      0.43      0.57       767\n",
      "\n",
      "    accuracy                           0.68      1550\n",
      "   macro avg       0.73      0.67      0.66      1550\n",
      "weighted avg       0.73      0.68      0.66      1550\n",
      "\n",
      "\n",
      "\n",
      "Completion probability \n",
      " [[0.7130069  0.2869931 ]\n",
      " [0.6885272  0.31147274]\n",
      " [0.53976977 0.46023026]\n",
      " ...\n",
      " [0.05363178 0.9463682 ]\n",
      " [0.1628412  0.8371588 ]\n",
      " [0.62575376 0.37424624]]\n"
     ]
    }
   ],
   "source": [
    "#passing the test data here\n",
    "accuracy, report, completion_probability = predict_with_xgboost(test_data)\n",
    "\n",
    "print('Accuracy score ', accuracy)\n",
    "print('\\n')\n",
    "print('Classification report \\n\\n', report)\n",
    "print('\\n')\n",
    "print('Completion probability \\n', completion_probability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
